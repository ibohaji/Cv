{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg') \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np \n",
    "from scipy.spatial.transform import Rotation\n",
    "from some import add_project_root_to_path\n",
    "\n",
    "add_project_root_to_path()\n",
    "\n",
    "\n",
    "K = np.array([[1000,0,300],[0,1000,200],[0,0,1]])\n",
    "R1,t1 = np.eye(3),np.array([0,0,0])\n",
    "\n",
    "R2 = Rotation.from_euler('xyz', [0.7, -0.5, 0.8]).as_matrix()\n",
    "t2 = np.array([0.2,2,1])\n",
    "\n",
    "# Projection matrix for Cam1 and Cam2 \n",
    "\n",
    "P1 = K @ np.column_stack((R1,t1.reshape(3,1)))\n",
    "P2 = K @ np.column_stack((R2,t2.reshape(3,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1\n",
    "Consider the 3D point\n",
    "$Q = [1,0.5,4,1]$\n",
    "\n",
    " and find the projections in Cam1 and Cam2, respectively, points q1 and q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([1,0.5,4,1]).reshape(4,1)\n",
    "\n",
    "# Projecting the 3D point to 2D\n",
    "q1 = P1 @ Q\n",
    "q2 = P2 @ Q\n",
    "\n",
    "#Normalizing the coordinates\n",
    "q1 = q1/q1[2]\n",
    "q2 = q2/q2[2] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2\n",
    "\n",
    "Implement a function `CrossOp` that takes a vector in 3D and returns the 3×3 matrix corresponding to taking the cross product with that vector. In the case that $p = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix}^T$, you should have:\n",
    "\n",
    "$$\n",
    "CrossOp(p) = [p]× =\n",
    "\\begin{bmatrix}\n",
    "0 & -z & y \\\\\n",
    "z & 0 & -x \\\\\n",
    "-y & x & 0\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "As always, verify that your function works. In this case, you can test it on random vectors and ensure that:\n",
    "\n",
    "$$\n",
    "[p1]×p2 = p1 \\times p2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implemented in the functions.py file\n",
    "def crossOp(p): \n",
    "    p_cross = np.array([[0,-p[2],p[1]],[p[2],0,-p[0]],[-p[1],p[0],0]]) \n",
    "    return p_cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "- Compute the fundamental matrix F of the two cameras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental matrix can be computed from the essential matrix as \n",
    "\n",
    "$$ \\Large \n",
    "F = A_2^{-T} \\space  E \\space  A_1^{-1}\n",
    "$$\n",
    "\n",
    "Where $$\\Large E = \\space [t]_x \\space \\space R $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative Rotation R from camera 1 to camera 2 can be calculated as  \n",
    "\n",
    "$$ \\Large \n",
    "R = R_2 R^T\n",
    "$$ \n",
    "\n",
    "and And the relative translation T can be calculated as \n",
    "\n",
    "$$ \\Large \n",
    "t = t2 - R_2R_1^Tt_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.29311881e-07  8.19396327e-07  1.79162592e-03]\n",
      " [ 5.15532551e-07 -8.76915984e-07  9.31426656e-05]\n",
      " [-1.29882755e-03  1.51951700e-03 -1.10072682e+00]]\n"
     ]
    }
   ],
   "source": [
    "R = R2 @ R1.T\n",
    "t = t2 - R2 @ R1.T @ t1 \n",
    "E = crossOp(t) @ R \n",
    "F = np.linalg.inv(K).T @ E @ np.linalg.inv(K)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4\n",
    "- What is the epipolar line l of q1 in camera two?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epipolar line l of q1 in camera two \n",
    "is $l = Fq$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.23905126e-03],\n",
       "       [ 9.16878739e-05],\n",
       "       [-1.32123895e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = F @ q1 \n",
    "l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.5\n",
    "- Is q2 located on the epipolar line from Exercise 3.4? \n",
    "- Do the computations, but also explain why\n",
    "this must be so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4408921e-16]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To determine whether the point q2 is located on the epipolar line \n",
    "# we can check if the product of q2.T @ l1 is close to zero \n",
    "\n",
    "q2.T @ l1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.6\n",
    "\n",
    "Now assume that both camera one and two have local coordinate systems that are different from the coordinate system of the world.\n",
    "\n",
    "Let $Q$ and $\\tilde{Q}$ denote the same 3D point in world space and in the frame of camera one. In other words, we have the relation:\n",
    "\n",
    "$$\n",
    "\\tilde{Q} =\n",
    "\\begin{bmatrix}\n",
    "R_1 & t_1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "Q. \\quad (13)\n",
    "$$\n",
    "\n",
    "Make sure you understand why this is true.\n",
    "\n",
    "Show analytically that:\n",
    "\n",
    "$$\n",
    "Q =\n",
    "\\begin{bmatrix}\n",
    "R_1^T & -R_1^T t_1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\tilde{Q}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------- \n",
    "Since the rotation and translation is set to world coordinate system, the pose matrix T maps from homogenous to inhom coordinates. \n",
    "\n",
    "$$\n",
    "Q =\n",
    "\\begin{bmatrix}\n",
    "R_1^T & -R_1^T t_1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\tilde{Q}.\n",
    "\n",
    "\\implies Q = \\begin{bmatrix}\n",
    "R_1^T & -R_1^T t_1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} \n",
    " \\begin{bmatrix}\n",
    "R_1 & t_1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "Q\n",
    "$$\n",
    "\n",
    "$$\n",
    " \\implies Q = \n",
    "\\begin{bmatrix}\n",
    "R_1^T R_1 & R_1^T t_1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} Q \n",
    "\n",
    "$$\n",
    "\n",
    "This simplifies to \n",
    "\n",
    "$$\n",
    " \\implies Q = \n",
    "\\begin{bmatrix}\n",
    "I & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} Q \n",
    "\n",
    "$$\n",
    "\n",
    "Since according to Appendix A.4 in the lecture notes (page 198), $R^TR = I$\n",
    "\n",
    "And the above expression simplifies to Q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "### Exercise 3.8\n",
    "\n",
    "Load the file TwoImageDataCar.npy, and compute the fundamental matrix between the images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.50228281e-08 -3.45997421e-07 -3.47606501e-05]\n",
      " [-2.06767970e-07  3.96284278e-08 -9.29558240e-04]\n",
      " [ 2.61581163e-05  1.12168578e-03  1.17449076e-02]]\n"
     ]
    }
   ],
   "source": [
    "path = \"../Data/\" \n",
    "Data = np.load(path + \"TwoImageDataCar.npy\",allow_pickle=True).item()\n",
    "\n",
    "K = Data['K']\n",
    "im1 = Data['im1']\n",
    "R1 = Data['R1']\n",
    "t1 = Data['t1']\n",
    "im2 = Data['im2']\n",
    "R2 = Data['R2']\n",
    "t2 = Data['t2']\n",
    "\n",
    "\n",
    "t = t2 - R2 @ R1.T @ t1\n",
    "R = R2 @ R1.T \n",
    "\n",
    "E = crossOp(t) @ R \n",
    "F = np.linalg.inv(K).T @ E @ np.linalg.inv(K) \n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "## Exercise 3.9\n",
    "\n",
    "Write code that can show both images at the same time. Now write code such that you can click on a point in image one, and display the corresponding epipolar line in image two. Experiment with your code, verifying that the point you click on is on the epipolar line in the other image.\n",
    "\n",
    "**Tip**: To click on a point and get the pixel coordinates, you can use `plt.ginput(1)`. This needs the figure to open in a new window, so you might need to run `%matplotlib qt` first.\n",
    "\n",
    "**Tip**: To draw a line given in homogeneous coordinates, you can use the `DrawLine` function below. It takes as input a line in homogeneous coordinates `l` and the size of the image it will be drawn on, as returned by `im.shape`.\n",
    "\n",
    "```python\n",
    "def DrawLine(l, shape):\n",
    "    # Checks where the line intersects the four sides of the image\n",
    "    # and finds the two intersections that are within the frame\n",
    "    def in_frame(l_im):\n",
    "        q = np.cross(l.flatten(), l_im)\n",
    "        q = q[:2] / q[2]\n",
    "        if all(q >= 0) and all(q + 1 <= shape[1::-1]):\n",
    "            return q\n",
    "    lines = [[1, 0, 0], [0, 1, 0], [1, 0, 1 - shape[1]], [0, 1, 1 - shape[0]]]\n",
    "    P = [in_frame(l_im) for l_im in lines if in_frame(l_im) is not None]\n",
    "    if len(P) == 0:\n",
    "        print(\"Line is completely outside image\")\n",
    "    plt.plot(*np.array(P).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.functions_10 import * \n",
    "\n",
    "def DrawLine(l, shape):\n",
    "#Checks where the line intersects the four sides of the image\n",
    "# and finds the two intersections that are within the frame\n",
    "    def in_frame(l_im):\n",
    "        q = np.cross(l.flatten(), l_im)\n",
    "        q = q[:2]/q[2]\n",
    "        if all(q>=0) and all(q+1<=shape[1::-1]):\n",
    "         return q\n",
    "    lines = [[1, 0, 0], [0, 1, 0], [1, 0, 1-shape[1]], [0, 1, 1-shape[0]]]\n",
    "    P = [in_frame(l_im) for l_im in lines if in_frame(l_im) is not None]\n",
    "    if (len(P)==0):\n",
    "        print(\"Line is completely outside image\")\n",
    "    else:\n",
    "       print(\"Line is partially inside image\")\n",
    "       \n",
    "    plt.plot(*np.array(P).T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Show_epipolar_line(im1,im2,K,F):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "    ax[0].imshow(im1)\n",
    "    ax[1].imshow(im2)\n",
    "    q1 = np.array(plt.ginput(1,0))\n",
    "    q1_inh = PiInv(q1.reshape(-1,1)).reshape(1,-1)\n",
    "    plt.axis('off')\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "    l2 = F @ q1_inh.T\n",
    "\n",
    "    DrawLine(l2,im2.shape)\n",
    "    ax[0].scatter(*q1.T, marker='x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line is partially inside image\n"
     ]
    }
   ],
   "source": [
    "Show_epipolar_line(im1,im2,K,F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- \n",
    "\n",
    "### Exercise 3.10\n",
    "\n",
    "\n",
    "Do the same thing as the last exercise, but where you can click in image two and get the epipolar\n",
    "line displayed in image one. You do not compute a new fundamental matrix to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawLine(l, shape, ax):\n",
    "    def in_frame(l_im):\n",
    "        q = np.cross(l.flatten(), l_im)\n",
    "        q = q[:2] / q[2]\n",
    "        if all(q >= 0) and all(q + 1 <= shape[1::-1]):\n",
    "            return q\n",
    "\n",
    "    lines = [[1, 0, 0], [0, 1, 0], [1, 0, 1 - shape[1]], [0, 1, 1 - shape[0]]]\n",
    "    P = [in_frame(l_im) for l_im in lines if in_frame(l_im) is not None]\n",
    "    if len(P) == 0:\n",
    "        print(\"Line is completely outside image\")\n",
    "    else:\n",
    "        print(\"Line is partially inside image\")\n",
    "        # Plot on the specified axes\n",
    "        ax.plot(*np.array(P).T, color='red')  # You can specify a color for clarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def Show_epipolar_line_2(im1, im2, K, F):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(im1)\n",
    "    ax[1].imshow(im2)\n",
    "    plt.show(block=False)\n",
    "    q2 = np.array(plt.ginput(1, timeout=0))  \n",
    "\n",
    "    q2_inh = PiInv(q2.reshape(-1, 1)).reshape(1, -1)  \n",
    "    l1 = q2_inh @ F  \n",
    "    l1 = l1.T\n",
    "    # Reopen the figure to plot the line\n",
    "    \n",
    "    DrawLine(l1.T, im1.shape, ax[0])  # Pass ax[0] to draw the line on the first image\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line is partially inside image\n"
     ]
    }
   ],
   "source": [
    "Show_epipolar_line_2(im1,im2,K,F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Exercise 3.11\n",
    "\n",
    "Create a function named `triangulate`. This function should be capable of triangulating a single 3D point that has been observed by multiple cameras. The function should adhere to the following specifications:\n",
    "\n",
    "### Function Specifications:\n",
    "- **Input:**\n",
    "  - A list of `n` pixel coordinates (q1, q2, ..., qn), representing the observations of the point in each camera's image plane.\n",
    "  - A list of `n` projection matrices (P1, P2, ..., Pn), where each matrix corresponds to a camera's projection matrix.\n",
    "- **Output:**\n",
    "  - The triangulated 3D point using a linear triangulation algorithm.\n",
    "\n",
    "### Testing the Function:\n",
    "1. **Define a 3D point**: Choose a point in 3D space.\n",
    "2. **Project this point onto the image planes of two cameras**: Use the projection matrices of at least two cameras to project the 3D point onto their respective image planes.\n",
    "3. **Triangulate the 3D point**: Using the projections obtained in the previous step, apply your `triangulate` function to estimate the location of the original 3D point.\n",
    "4. **Reproject the estimated 3D point back onto the image planes of the cameras**: Check if the reprojected 2D points coincide with the original pixel coordinates used for triangulation.\n",
    "\n",
    "### Questions:\n",
    "- After reprojecting your estimated 3D point to the cameras, do you find the same 2D pixels? Discuss any discrepancies or confirmations between the estimated coordinates and the original ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23408229, -0.11704115, -0.93632918, -0.23408229])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def triangulate(qn,pn):\n",
    "    \"\"\" \n",
    "    input:list of points qn and projection matrices Pn\"\"\"\n",
    "    if len(qn) != len(pn):\n",
    "        raise ValueError(\"Expected lists of equal length, len(Q)!=len(pn)\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    B_i = lambda P,q: np.array([  [P[2]*q[0] - P[0]],[P[2]*q[1] - P[1]]  ])\n",
    "\n",
    "    B = np.hstack(([B_i(P_i,Pi(q_i)) for P_i, q_i in zip(pn,qn)]))\n",
    "\n",
    "    B = B.reshape(len(pn)*2,4)\n",
    "    U,S,VT = np.linalg.svd(B)\n",
    "\n",
    "    Q = VT[-1,:]\n",
    "    return Q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "triangulate([q1,q2],[P1,P2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[550.]\n",
      " [325.]]\n",
      "[[582.47256835]\n",
      " [185.98985776]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test your function by defining a 3D point, project this point to the image planes of the two\n",
    "cameras, and then triangulate it using the projection. Try reprojecting your estimated 3D point\n",
    "to the cameras. Do you find the same 2D pixels?\"\"\"\n",
    "\n",
    "Q = np.array([1,0.5,4,1]).reshape(4,1)\n",
    "q1 = P1 @ Q \n",
    "q2 = P2 @ Q\n",
    "\n",
    "print((Pi(q1)))\n",
    "print((Pi(q2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550. 325.]\n",
      "[582.47256835 185.98985776]\n"
     ]
    }
   ],
   "source": [
    "Q_est = triangulate([q1,q2],[P1,P2]) \n",
    "q1_est = P1 @ Q_est\n",
    "q2_est = P2 @ Q_est\n",
    "\n",
    "print((Pi(q1_est)))\n",
    "print(Pi(q2_est))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.93331152, -0.07474679,  0.26000912, -0.2360885 ])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_est"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
